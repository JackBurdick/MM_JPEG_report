{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lossless JPEG Project\n",
    "Jack Burdick\n",
    "\n",
    "\n",
    "## Project Information\n",
    "We'll explore a, basic, handcrafted JPEG lossless encoder; We'll convert an image into a binary string that can then be recreated into the original image without loosing an details -- hence the lossless bit.\n",
    "\n",
    "##### NOTE:\n",
    "_This project uses an image of size 16x16 pixels.  These values are hardcoded into the project.  If you want to use an image of another size you can change the values.  Please also note that the image dimensions are not saved in the encoded string, meaning you'll have to ensure you take this into consideration when decoding._\n",
    "\n",
    "## Overview\n",
    "![Project Overview](./images/project_overview.png)\n",
    "From the above steps;\n",
    "1. We'll start with an matrix of integers, which we'll import as an image, \n",
    "2. Encode the image from an array of ints to a string of binary numbers\n",
    "    * Predict new value from the image (using a given predictor equation)\n",
    "    * Encode the difference\n",
    "3. Reverse these steps to recreate the image\n",
    "4. Evaluate the performance of the 7 difference predictors\n",
    "\n",
    "### What does the image look like?\n",
    "![image representation](./images/image_representation.png)\n",
    "\n",
    "\n",
    "## Predictor Equations\n",
    "### What is it?\n",
    "The predictor function creates a new value from the current JPEG image\n",
    "### Why do we need a new value?\n",
    "The original image has integer pixel values that range from [0-255]. This means that each pixel value requires at 8-bits -- 255 in binary is 8 bits (2^8 = 256).  The basic idea is that rather than encode these (potentially) large values that require 8 bits, we'll only encode a smaller value.  Enter the predictor equation.\n",
    "###  How does it work?\n",
    "Below (predictor functions) shows the 7 different cases we'll be using, but this block diagram shows the overview.  The idea is to take our matrix of pixel values, look at the values around a specific pixel value, then, depending on the predictor function, create a new value that is relative to these surrounding values.\n",
    "![predictor block](./images/predictor_block.png)\n",
    "\n",
    "### What do these predictor functions you speak of look like?\n",
    "These are the 7 predictor equations we'll be using - each labeled as case 0 through case 7\n",
    "![predictor functions](./images/predictor_functions.png)\n",
    "\n",
    "### I'll take, 'can you give me an example, Jack' for 200\n",
    "![predictor functions](./images/example_predictorFunction.png)\n",
    "\n",
    "##### But.. uhhh... so what about the values in the first row -- they don't have a `B` value.. AND! what about the values in the first column! -- they don't have a `A` value.. are you trying to pull a fast one on us?\n",
    "\n",
    "### Right, so the first column and first row all require special attention\n",
    "![predictor functions](./images/first_rowCol.png)\n",
    "\n",
    "### Why does this matter?\n",
    "In the final section we'll look at some performance metrics -- spoiler alert: the storage size of the image becomes smaller without sacrificing any image information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "We'll use python for this assignment and since there's a fair amount of code to explain, we'll create and talk through the script step by step.  The Results will then be displayed in-line after all calculations are made \n",
    "#### Imports\n",
    "We'll need:\n",
    "1. numpy\n",
    "    * matrix manipulations\n",
    "2. skimage\n",
    "    * view the image\n",
    "3. matplotlib\n",
    "    * creating figures\n",
    "4. math\n",
    "    * calculating square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "# jupyter notebook config: display the created plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to our selected 'array' of ints\n",
    "input_image_asTXT_path = './image_input.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in original image from txt file (received format) and convert image to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_image_matrix(input_image_asTXT_path, img_height, img_width):\n",
    "    # create a matrix of the proper size\n",
    "    original_image = np.zeros((img_width, img_height))\n",
    "    # fill empty matrix with specified values\n",
    "    with open(input_image_asTXT_path) as inVals:\n",
    "        img_row = []\n",
    "        row_num = 0\n",
    "        for line in inVals:\n",
    "            line = line.strip(\"\\n\")\n",
    "            line_list = line.split(\" \")\n",
    "            line_l_clean = [int(val.strip(\" \")) for val in line_list if val != \"\"]\n",
    "            # print(line_l_clean)\n",
    "            original_image[row_num] = line_l_clean\n",
    "            row_num += 1\n",
    "    return original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_image = create_image_matrix(input_image_asTXT_path, 16, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `original_image` holds our image.. Let's inspect to ensure we've captured it correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image:\n",
      " [[  88.   88.   88.   89.   90.   91.   92.   93.   94.   95.   93.   95.\n",
      "    96.   98.   97.   94.]\n",
      " [  93.   91.   91.   90.   92.   93.   94.   94.   95.   95.   92.   93.\n",
      "    95.   95.   95.   96.]\n",
      " [  95.   95.   95.   95.   96.   97.   94.   96.   97.   96.   98.   97.\n",
      "    98.   99.   95.   97.]\n",
      " [  97.   96.   98.   97.   98.   94.   95.   97.   99.  100.   99.  101.\n",
      "   100.  100.   98.   98.]\n",
      " [  99.  100.   97.   99.  100.  100.   98.   98.  100.  101.  100.   99.\n",
      "   101.  102.   99.  100.]\n",
      " [ 100.  101.  100.   99.  101.  102.   99.  100.  103.  102.  103.  101.\n",
      "   101.  100.  102.  101.]\n",
      " [ 100.  102.  103.  101.  101.  100.  102.  103.  103.  105.  104.  104.\n",
      "   103.  104.  104.  103.]\n",
      " [ 103.  105.  103.  105.  105.  104.  104.  104.  102.  101.  100.  100.\n",
      "   100.  101.  102.  103.]\n",
      " [ 104.  104.  105.  105.  105.  104.  104.  106.  102.  103.  101.  101.\n",
      "   102.  101.  102.  102.]\n",
      " [ 102.  105.  105.  105.  106.  104.  106.  104.  103.  101.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 102.  105.  105.  105.  106.  104.  106.  104.  103.  101.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 102.  105.  105.  105.  106.  104.  105.  104.  103.  101.  102.  100.\n",
      "   102.  102.  102.  103.]\n",
      " [ 104.  105.  106.  105.  106.  104.  106.  103.  103.  102.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 103.  105.  107.  107.  106.  104.  106.  104.  103.  101.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 103.  105.  106.  108.  106.  104.  106.  105.  103.  101.  101.  100.\n",
      "   101.  103.  102.  105.]\n",
      " [ 102.  105.  105.  105.  106.  104.  106.  107.  104.  103.  102.  100.\n",
      "   101.  104.  102.  104.]]\n",
      "Image dimensions: (16, 16)\n"
     ]
    }
   ],
   "source": [
    "# print raw matrix values\n",
    "print(\"Original Image:\\n\", original_image)\n",
    "# print shape\n",
    "print(\"Image dimensions:\", original_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good here; it matches the expected values from the input txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect grayscale image to satisfy curiosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1137d8ef0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nViiH36xQDr9Zof4fRlKZHnduh6UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114b217b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little less excting than I was hoping for.. but let's move on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Calculations\n",
    "### Given: 7 predictor equations\n",
    "### Plan\n",
    "* Input\n",
    "    * Image matrix of raw values\n",
    "        * `original_image`\n",
    "        * `CASE`\n",
    "* Implementation\n",
    "    * Create a function (`prediction_generator()`) that generates the predicted value, given A,B,C, the current value, and the specified case\n",
    "    * Given the above function, create a function (`create_differences_matrix_with_case()`) that, using a parameter flag, uses the specified predictor and outputs the predicted value\n",
    "* Output\n",
    "    * A Matrix of the difference values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_generator(cur_val, case, values):\n",
    "    A = values[0]\n",
    "    B = values[1]\n",
    "    C = values[2]\n",
    "\n",
    "    # this flag will go high when there is potential for a float value difference to be generated\n",
    "    float_flag = False\n",
    "\n",
    "    if(case == 0):\n",
    "        val_not = A\n",
    "    elif(case == 1):\n",
    "        val_not = B\n",
    "    elif(case == 2):\n",
    "        val_not = C\n",
    "    elif(case == 3):\n",
    "        val_not = A + B - C\n",
    "    elif(case == 4):\n",
    "        val_not = A + ((B - C)/2)\n",
    "        float_flag = True\n",
    "    elif(case == 5):\n",
    "        val_not = B + ((A - C)/2)\n",
    "        float_flag = True\n",
    "    elif(case == 6):\n",
    "        val_not = (A + B)/2\n",
    "        float_flag = True\n",
    "    else:\n",
    "        print(\"we didn't plan for this....\")\n",
    "\n",
    "    diff = cur_val - val_not\n",
    "\n",
    "    # to account for the float, we will multiply all values\n",
    "    # for the specific case by 2 to ensure we return an integer\n",
    "    # this will be important when encoding/decoding\n",
    "    if float_flag:\n",
    "        # pass\n",
    "        diff_double = diff * 2\n",
    "        diff = diff_double\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special considerations\n",
    "The first column and first row of the images require 'special treatment'.\n",
    "* The first row doesn't have a value above it (B)\n",
    "* The first column doesn't have a value to the left of it (A)\n",
    "* Neither the first column, nor the first row, have a value to the upper left of them (C)\n",
    "\n",
    "This will be taken into account (as shown in the above function) by implementing independent functions for the first row and first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# handle the first row of the image values\n",
    "def get_pred_row_1(row, cur_col):\n",
    "    # pred = current - (A)left\n",
    "    A_val = row[cur_col - 1]\n",
    "    x_val = row[cur_col]\n",
    "    pred = x_val - A_val\n",
    "    # DEBUGGING: print statement showing pred calc\n",
    "    # print(\"A(\", A_val, \")\", \"-\", \"cur(\", x_val, \")\", \" = \", pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# handle the first column of the image values\n",
    "def get_pred_col_1(cur_row, cur_col, original_image):\n",
    "    # pred = current - (B)above\n",
    "    B_val = original_image[cur_row-1][cur_col]\n",
    "    x_val = original_image[cur_row][cur_col]\n",
    "    pred = x_val - B_val\n",
    "    # DEBUGGING: print statement showing pred calc\n",
    "    # print(\"cur(\", x_val, \")\", \"-\", \"B(\", B_val, \")\", \" = \", pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create prediction matrix\n",
    "# this uses the prediction_generator to get each value\n",
    "def create_differences_matrix_with_case(original_image, case):\n",
    "\n",
    "    # create difference matrix\n",
    "    img_width, img_height = original_image.shape \n",
    "    diff_matrix = np.zeros((img_width, img_height))\n",
    "    \n",
    "    # index values\n",
    "    cur_row = 0\n",
    "    cur_col = 0\n",
    "\n",
    "    # copy first value\n",
    "    diff_matrix[cur_row][cur_col] = original_image[cur_row][cur_col]\n",
    "    # loop rows in the image\n",
    "    for row in original_image:\n",
    "        # first row is a special case\n",
    "        if cur_row == 0:\n",
    "            cur_col = 0\n",
    "            for col_val in row:\n",
    "                # the first value is already copied\n",
    "                if cur_col != 0:\n",
    "                    value = get_pred_row_1(row, cur_col)\n",
    "                    diff_matrix[cur_row][cur_col] = value\n",
    "                cur_col += 1\n",
    "        else:\n",
    "            cur_col = 0\n",
    "            for col_val in row:\n",
    "                if cur_col == 0:\n",
    "                    diff_value = get_pred_col_1(cur_row,\n",
    "                                                cur_col,\n",
    "                                                original_image)\n",
    "                    diff_matrix[cur_row][cur_col] = diff_value\n",
    "                else:\n",
    "                    # Main implementation (first row/col have been calculated)\n",
    "                    # get prediction according to case\n",
    "                    current_val = original_image[cur_row][cur_col]\n",
    "                    A = original_image[cur_row][cur_col-1]\n",
    "                    B = original_image[cur_row-1][cur_col]\n",
    "                    C = original_image[cur_row-1][cur_col-1]\n",
    "                    values = [A, B, C]\n",
    "                    diff_value = prediction_generator(current_val,\n",
    "                                                      case,\n",
    "                                                      values)\n",
    "                    diff_matrix[cur_row][cur_col] = diff_value\n",
    "                cur_col += 1\n",
    "        cur_row += 1\n",
    "    return diff_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that our difference matrix is being generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 88.   0.   0.   1.   1.   1.   1.   1.   1.   1.  -2.   2.   1.   2.\n",
      "   -1.  -3.]\n",
      " [  5.  -2.   0.  -1.   2.   1.   1.   0.   1.   0.  -3.   1.   2.   0.\n",
      "    0.   1.]\n",
      " [  2.   0.   0.   0.   1.   1.  -3.   2.   1.  -1.   2.  -1.   1.   1.\n",
      "   -4.   2.]\n",
      " [  2.  -1.   2.  -1.   1.  -4.   1.   2.   2.   1.  -1.   2.  -1.   0.\n",
      "   -2.   0.]\n",
      " [  2.   1.  -3.   2.   1.   0.  -2.   0.   2.   1.  -1.  -1.   2.   1.\n",
      "   -3.   1.]\n",
      " [  1.   1.  -1.  -1.   2.   1.  -3.   1.   3.  -1.   1.  -2.   0.  -1.\n",
      "    2.  -1.]\n",
      " [  0.   2.   1.  -2.   0.  -1.   2.   1.   0.   2.  -1.   0.  -1.   1.\n",
      "    0.  -1.]\n",
      " [  3.   2.  -2.   2.   0.  -1.   0.   0.  -2.  -1.  -1.   0.   0.   1.\n",
      "    1.   1.]\n",
      " [  1.   0.   1.   0.   0.  -1.   0.   2.  -4.   1.  -2.   0.   1.  -1.\n",
      "    1.   0.]\n",
      " [ -2.   3.   0.   0.   1.  -2.   2.  -2.  -1.  -2.  -1.   0.   1.   1.\n",
      "    0.   1.]\n",
      " [  0.   3.   0.   0.   1.  -2.   2.  -2.  -1.  -2.  -1.   0.   1.   1.\n",
      "    0.   1.]\n",
      " [  0.   3.   0.   0.   1.  -2.   1.  -1.  -1.  -2.   1.  -2.   2.   0.\n",
      "    0.   1.]\n",
      " [  2.   1.   1.  -1.   1.  -2.   2.  -3.   0.  -1.  -2.   0.   1.   1.\n",
      "    0.   1.]\n",
      " [ -1.   2.   2.   0.  -1.  -2.   2.  -2.  -1.  -2.  -1.   0.   1.   1.\n",
      "    0.   1.]\n",
      " [  0.   2.   1.   2.  -2.  -2.   2.  -1.  -2.  -2.   0.  -1.   1.   2.\n",
      "   -1.   3.]\n",
      " [ -1.   3.   0.   0.   1.  -2.   2.   1.  -3.  -1.  -1.  -2.   1.   3.\n",
      "   -2.   2.]]\n"
     ]
    }
   ],
   "source": [
    "diff_matrix = create_differences_matrix_with_case(original_image, 0)\n",
    "print(diff_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. How about for the cases when a float value could be created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 88.   0.   0.   1.   1.   1.   1.   1.   1.   1.  -2.   2.   1.   2.\n",
      "   -1.  -3.]\n",
      " [  5.   1.   3.  -1.   3.   2.   2.   0.   1.  -1.  -2.  -3.   0.  -5.\n",
      "   -1.   6.]\n",
      " [  2.   6.   4.   6.   3.   4.  -4.   4.   2.   0.  11.   2.   2.   5.\n",
      "   -4.   2.]\n",
      " [  2.   0.   5.   1.   2.  -8.   5.   1.   3.   6.  -2.   7.   0.   0.\n",
      "    5.  -1.]\n",
      " [  2.   6.  -6.   5.   2.  10.   0.  -1.   1.   1.   1.  -5.   4.   3.\n",
      "    0.   3.]\n",
      " [  1.   1.   5.  -3.   2.   3.   0.   3.   4.  -1.   5.   1.  -2.  -4.\n",
      "    8.  -1.]\n",
      " [  0.   2.   5.   1.  -2.  -4.   8.   3.  -3.   6.  -1.   5.   1.   6.\n",
      "    0.   2.]\n",
      " [  3.   3.  -3.   8.   4.   4.   0.   0.  -3.  -7.  -4.  -4.  -2.  -3.\n",
      "   -1.   2.]\n",
      " [  1.  -3.   5.  -2.   0.   0.   0.   4.  -2.   4.   0.   1.   3.  -2.\n",
      "    0.  -2.]\n",
      " [ -2.   4.  -1.   0.   2.  -1.   4.  -6.   4.  -5.   0.  -1.  -1.   3.\n",
      "   -1.   2.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  -2.   1.   0.   0.   4.  -2.   2.  -1.\n",
      "    0.   0.]\n",
      " [  2.  -2.   2.  -1.   0.   0.   2.  -3.   1.   2.  -5.   2.  -2.   1.\n",
      "    0.   0.]\n",
      " [ -1.   1.   2.   3.  -2.   0.   0.   2.  -1.  -2.   1.   0.   0.   0.\n",
      "    0.   0.]\n",
      " [  0.   0.  -2.   3.  -1.   0.   0.   2.  -1.   0.   2.  -1.   0.   2.\n",
      "   -1.   4.]\n",
      " [ -1.   1.  -2.  -5.   3.   0.   0.   4.   0.   3.   0.  -1.   0.   2.\n",
      "   -1.  -2.]]\n"
     ]
    }
   ],
   "source": [
    "diff_matrix = create_differences_matrix_with_case(original_image, 5)\n",
    "print(diff_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working as intended.. note that the values go much higher here.. in one case the value is 11!\n",
    "\n",
    "#### Overview to expand on the encoding/decoding scheme\n",
    "1. View the current encoding/decoding scheme\n",
    "2. Ensure reproducible pattern exists (it should, it's huffman encoding)\n",
    "3. Create a custom function to expand on this\n",
    "4. Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '1', 1: '00', 2: '0100', 3: '010100', 4: '01010100', 5: '0101010100', 6: '010101010100', -2: '01011', -6: '0101010101011', -5: '01010101011', -4: '010101011', -3: '0101011', -1: '011'}\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "huffan_lookup_txt_path = './huffman_tb_dx_input.txt'\n",
    "test_huffman_dict = {}\n",
    "with open(huffan_lookup_txt_path) as lookupVals:\n",
    "    for line in lookupVals:\n",
    "        line = line.strip(\"\\n\")\n",
    "        cur_pair = line.split(\",\")\n",
    "        cur_key = int(cur_pair[0])\n",
    "        cur_val = cur_pair[1]\n",
    "        test_huffman_dict[cur_key] = cur_val\n",
    "\n",
    "# step 2\n",
    "print(test_huffman_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2': '0100', '11': '0101010101010101010100', '12': '010101010101010101010100', '-10': '010101010101010101011', '-9': '0101010101010101011', '1': '00', '-2': '01011', '10': '01010101010101010100', '-12': '0101010101010101010101011', '-4': '010101011', '9': '010101010101010100', '-11': '01010101010101010101011', '4': '01010100', '-3': '0101011', '-5': '01010101011', '6': '010101010100', '8': '0101010101010100', '5': '0101010100', '-8': '01010101010101011', '3': '010100', '7': '01010101010100', '0': '1', '-6': '0101010101011', '-7': '010101010101011', '-1': '011'}\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "def create_bin_dict(MAX_LEN):\n",
    "    created_dict = {}\n",
    "    created_dict['0'] = '1'\n",
    "    max_len = MAX_LEN\n",
    "    # add positives\n",
    "    pos_end_string = '00'\n",
    "    val = 0\n",
    "    while val <= max_len:\n",
    "        cur_string = ''\n",
    "        i = 0\n",
    "        while i < val:\n",
    "            cur_string += '01'\n",
    "            i += 1\n",
    "        val += 1\n",
    "        cur_string += pos_end_string\n",
    "        created_dict[str(val)] = cur_string\n",
    "        # print(\"val: \", val, \"string: \\t\", cur_string)\n",
    "\n",
    "    # add negatives\n",
    "    neg_end_string = '1'\n",
    "    val = -0\n",
    "    while val >= -max_len:\n",
    "        cur_string = ''\n",
    "        i = 0\n",
    "        while i >= val:\n",
    "            cur_string += '01'\n",
    "            i -= 1\n",
    "        val -= 1\n",
    "        cur_string += neg_end_string\n",
    "        created_dict[str(val)] = cur_string\n",
    "        # print(\"-val: \", val, \"string: \\t\", cur_string)\n",
    "    return created_dict\n",
    "\n",
    "# step 4\n",
    "# we'll be using 11 as the max length because I know this will handle all cases for the given image\n",
    "huffman_dict = create_bin_dict(11)\n",
    "print(huffman_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: \n",
    "Rather than create a new dictionary for each value, based on the max absolute difference value, we will create a single globally scoped `huffman_dict` that we can access.  This would not scale well, but creating the trivial and isn't important to this report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "Though the dictionary works well for converting an int to binary string, We also need to be able to convert the first value in the matrix to a binary string.  This first value is always 8 bits.  Rather than hard code this we'll use a python conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01000011\n"
     ]
    }
   ],
   "source": [
    "# test binary converstion\n",
    "test_bin_int = 67\n",
    "test_bin_string = '{0:08b}'.format(test_bin_int)\n",
    "print(test_bin_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, that' works; `67` in binary is `01000011`\n",
    "We'll need this for our next function\n",
    "\n",
    "# Overview: where are we so far\n",
    "Right now we have:\n",
    "* Image Matrix\n",
    "    * `original_image`\n",
    "* Predicted values -> Difference Matrix\n",
    "    * `diff_matrix`\n",
    "* An encoding scheme\n",
    "    * `huffman_dict`\n",
    "\n",
    "# What's next\n",
    "1. Encode to binary string\n",
    "    * The 'heavy lifting' is already done here\n",
    "2. Decode back to original image\n",
    "    * Essentially just reverse what we've already done\n",
    "3. Test all cases and make sure all image values are stored\n",
    "    * Since we're passing everything as flags/values, we should be able to easily test all cases\n",
    "4. Compare/contrast methods\n",
    "    * Better get some popcorn, this is bound to be a thriller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given the diff_matrix and encoding scheme, we can quickly create the binary string\n",
    "def encode_diffMatrix(diff_matrix, huffman_dict):\n",
    "    # loop through image\n",
    "    row_ind = 0\n",
    "    # col_index = 0\n",
    "    encoded_string = \"\"\n",
    "    for row in diff_matrix:\n",
    "        col_index = 0\n",
    "        for col_val in row:\n",
    "            if row_ind == 0 and col_index == 0:\n",
    "                # this is where the above conversion comes in handy\n",
    "                val_int = int(diff_matrix[row_ind][col_index])\n",
    "                encoded_value = '{0:08b}'.format(val_int)\n",
    "            else:\n",
    "                cur_val = diff_matrix[row_ind][col_index]\n",
    "                encoded_value = huffman_dict[str(int(cur_val))]\n",
    "            encoded_string += encoded_value\n",
    "            col_index += 1\n",
    "        row_ind += 1\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0101100011000000000000000101101000001000110101011010101010000010100011010100010001001000110101101010111010101010110110101010101000100010101010100010101000101010101000101000101010001010101101010100010010101010101010101010100010001000101010100010101011010001001010101010000010001010101010101011010101010000010100010101010100010110101010101010011010101010001101000101010101000101010101011010101010001000101010101010101010010110000000101010101101010100010100101010000000101010100010101101000101001010100010101000110101010100000101101010101101010101010101000111010001010101000001011010101011010101010101010001010001010110101010101000110101010100000101010101001010001010001010001010110101010101010100010101000101010011010101101010101010101101010101101010101101011010101101101000001010110101010100010111110101010001011010101001000101000101110101101011010101000111010001101010100010101010101101010100010101010111011011010100011010011111111111111111111110101100110101010001011010001111010001011010001111010001010110001000101010101101000101100110110001000101000101111010001101011001111111010110101000111101000111010001110100011010101000110001011010101010110101001101010100101010010111010001101011\n"
     ]
    }
   ],
   "source": [
    "# test to ensure we're creating a string\n",
    "encoded_string = encode_diffMatrix(diff_matrix, huffman_dict)\n",
    "print(encoded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From binary string to JPEG\n",
    "Now that we've converted to a binary string we have to start the process of decoding a binary string to a JPEG image.\n",
    "\n",
    "### Plan:\n",
    "1. Write a single function that\n",
    "    * takes inputs:\n",
    "        * binary encoded string\n",
    "        * target image width and height\n",
    "        * a decoding dictionary scheme\n",
    "        * the case (reverse predictor to use)\n",
    "    * Returns:\n",
    "        * image matrix\n",
    "        \n",
    "Note, we want to ensure we don't pass the original image (we are 'recreating' it from the binary string).\n",
    "\n",
    "### Note:\n",
    "Since this decoding is identical to encoding (only in reverse) I will not be explaining every step in detail.  If you have questions about this, please feel free to email me\n",
    "\n",
    "#### First\n",
    "1. we have to create a reverse dictionary that is the same as the current dictionary, only in reverse since we now want to go from binary to int\n",
    "2. we'll need special functions to handle the first column and first rows again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse huffman dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "huffman_dict_rev = {val: key for key, val in huffman_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get image height and width from the original image (ideally this would be encoded in the string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = original_image.shape\n",
    "print(img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculated decoded value according to our 7 cases\n",
    "def decode_val_from_case(case, row_index, col_index, created_dif_matrix, img_frm_decoded):\n",
    "    \n",
    "    cur_diff = created_dif_matrix[row_index][col_index]\n",
    "\n",
    "    A = img_frm_decoded[row_index][col_index-1]\n",
    "    B = img_frm_decoded[row_index-1][col_index]\n",
    "    C = img_frm_decoded[row_index-1][col_index-1]\n",
    "\n",
    "    float_flag = False\n",
    "    if(case == 0):\n",
    "        cmp_val = A\n",
    "    elif(case == 1):\n",
    "        cmp_val = B\n",
    "    elif(case == 2):\n",
    "        cmp_val = C\n",
    "    elif(case == 3):\n",
    "        cmp_val = A + B - C\n",
    "    elif(case == 4):\n",
    "        cmp_val = A + ((B - C)/2)\n",
    "        float_flag = True\n",
    "    elif(case == 5):\n",
    "        cmp_val = B + ((A - C)/2)\n",
    "        float_flag = True\n",
    "    elif(case == 6):\n",
    "        cmp_val = (A + B)/2\n",
    "        float_flag = True\n",
    "    else:\n",
    "        print(\"we didn't plan for this....\")\n",
    "\n",
    "    if float_flag:\n",
    "        cur_diff /= 2\n",
    "\n",
    "    new_val = cmp_val + cur_diff\n",
    "    # print(new_val)\n",
    "    return new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_first_row_val(cur_index, created_dif_matrix, img_frm_decoded):\n",
    "    # new_val = left(A) + diff\n",
    "    cur_diff = created_dif_matrix[0][cur_index]\n",
    "    A_val = img_frm_decoded[0][cur_index - 1]\n",
    "    img_val = A_val + cur_diff\n",
    "    return img_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_first_col_val(cur_row_index, cur_col_index,\n",
    "                         created_dif_matrix, img_frm_decoded):\n",
    "    # new_val = above(B) + diff\n",
    "    cur_diff = created_dif_matrix[cur_row_index][cur_col_index]\n",
    "    B_val = img_frm_decoded[cur_row_index - 1][cur_col_index]\n",
    "    img_val = B_val + cur_diff\n",
    "    return img_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_binaryString_to_diff_matrix(encoded_string,\n",
    "                                       img_width,\n",
    "                                       img_height,\n",
    "                                       huffman_dict_rev,\n",
    "                                       case):\n",
    "    created_dif_matrix = np.zeros((img_width, img_height))\n",
    "    i = 0\n",
    "    cur_seq = \"\"\n",
    "    first_num = encoded_string[:8]\n",
    "    # convert to int\n",
    "    first_img_val = int(first_num, 2)\n",
    "    val_list = []\n",
    "    val_list.append(first_img_val)\n",
    "    img_values = encoded_string[8:]\n",
    "    for bin_seq in img_values:\n",
    "        cur_seq += bin_seq\n",
    "        if cur_seq in huffman_dict_rev:\n",
    "            val_int = huffman_dict_rev[cur_seq]\n",
    "            # DEBUGGING: print statement to ensure conversion\n",
    "            # print(\"#\", i, \": \", cur_seq, \" = \", val_int)\n",
    "            val_list.append(int(val_int))\n",
    "            cur_seq = \"\"\n",
    "            i += 1\n",
    "\n",
    "    cur_col_index = 0\n",
    "\n",
    "    # recreate diff matrix\n",
    "    img_row_index = 0\n",
    "    img_col_index = 0\n",
    "    for val in val_list:\n",
    "        if img_col_index == img_width:\n",
    "            img_row_index += 1\n",
    "            img_col_index = 0\n",
    "        created_dif_matrix[img_row_index][img_col_index % img_width] = val\n",
    "        img_col_index += 1\n",
    "\n",
    "    # Show that we've recreated the difference matrix\n",
    "    # print(\"CREATED DIF MATRIX\")\n",
    "    # print(created_dif_matrix)\n",
    "\n",
    "    # create first row in recreated img\n",
    "    img_frm_decoded = np.zeros((img_width, img_height))\n",
    "    img_frm_decoded[0][0] = created_dif_matrix[0][0]\n",
    "\n",
    "    # loop through each row\n",
    "    row_index = 0\n",
    "    for diff_row in created_dif_matrix:\n",
    "        col_index = 0\n",
    "        # handle special case for first row\n",
    "        if row_index == 0:\n",
    "            # start at 1 since the first value is already handled\n",
    "            col_index += 1\n",
    "            while col_index < img_width:\n",
    "                val = decode_first_row_val(col_index,\n",
    "                                           created_dif_matrix,\n",
    "                                           img_frm_decoded)\n",
    "                img_frm_decoded[row_index][col_index] = val\n",
    "                col_index += 1\n",
    "        else:\n",
    "            while col_index < img_width:\n",
    "                if col_index == 0:\n",
    "                    # handle special case first column value\n",
    "                    val = decode_first_col_val(row_index, col_index,\n",
    "                                               created_dif_matrix,\n",
    "                                               img_frm_decoded)\n",
    "                    img_frm_decoded[row_index][col_index] = val\n",
    "                    col_index += 1\n",
    "                else:\n",
    "                    # Main implementation\n",
    "                    val = decode_val_from_case(case,\n",
    "                                               row_index, col_index,\n",
    "                                               created_dif_matrix,\n",
    "                                               img_frm_decoded)\n",
    "                    img_frm_decoded[row_index][col_index] = val\n",
    "                    col_index += 1\n",
    "        row_index += 1\n",
    "\n",
    "    return img_frm_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  88.   88.   88.   89.   90.   91.   92.   93.   94.   95.   93.   95.\n",
      "    96.   98.   97.   94.]\n",
      " [  93.   91.   91.   90.   92.   93.   94.   94.   95.   95.   92.   93.\n",
      "    95.   95.   95.   96.]\n",
      " [  95.   95.   95.   95.   96.   97.   94.   96.   97.   96.   98.   97.\n",
      "    98.   99.   95.   97.]\n",
      " [  97.   96.   98.   97.   98.   94.   95.   97.   99.  100.   99.  101.\n",
      "   100.  100.   98.   98.]\n",
      " [  99.  100.   97.   99.  100.  100.   98.   98.  100.  101.  100.   99.\n",
      "   101.  102.   99.  100.]\n",
      " [ 100.  101.  100.   99.  101.  102.   99.  100.  103.  102.  103.  101.\n",
      "   101.  100.  102.  101.]\n",
      " [ 100.  102.  103.  101.  101.  100.  102.  103.  103.  105.  104.  104.\n",
      "   103.  104.  104.  103.]\n",
      " [ 103.  105.  103.  105.  105.  104.  104.  104.  102.  101.  100.  100.\n",
      "   100.  101.  102.  103.]\n",
      " [ 104.  104.  105.  105.  105.  104.  104.  106.  102.  103.  101.  101.\n",
      "   102.  101.  102.  102.]\n",
      " [ 102.  105.  105.  105.  106.  104.  106.  104.  103.  101.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 102.  105.  105.  105.  106.  104.  106.  104.  103.  101.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 102.  105.  105.  105.  106.  104.  105.  104.  103.  101.  102.  100.\n",
      "   102.  102.  102.  103.]\n",
      " [ 104.  105.  106.  105.  106.  104.  106.  103.  103.  102.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 103.  105.  107.  107.  106.  104.  106.  104.  103.  101.  100.  100.\n",
      "   101.  102.  102.  103.]\n",
      " [ 103.  105.  106.  108.  106.  104.  106.  105.  103.  101.  101.  100.\n",
      "   101.  103.  102.  105.]\n",
      " [ 102.  105.  105.  105.  106.  104.  106.  107.  104.  103.  102.  100.\n",
      "   101.  104.  102.  104.]]\n"
     ]
    }
   ],
   "source": [
    "# test case\n",
    "case = 5\n",
    "test_re_created_img = decode_binaryString_to_diff_matrix(encoded_string,\n",
    "                                       img_width,\n",
    "                                       img_height,\n",
    "                                       huffman_dict_rev,\n",
    "                                       case)\n",
    "\n",
    "# this should be a matrix that matches our original matrix\n",
    "print(test_re_created_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks similar, let's test it by comparing the two matrixes (original and recreated) in image representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_side_by_side_figure(original_image, recreated_img, CURCASE):\n",
    "    # plt.figure(figsize=(6, 3))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    axes[0].imshow(original_image, cmap='gray')\n",
    "    axes[0].set_title(\"Original\")\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    axes[1].imshow(recreated_img, cmap='gray')\n",
    "    title = \"Case: \" + str(CURCASE)\n",
    "    axes[1].set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAADHCAYAAAAeaDj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMvP/UNciasLsO2IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11494c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_side_by_side_figure(original_image, test_re_created_img, case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## They look the same!\n",
    "This is good news, it means that for the given predictor method, we have succuessfully encoded and decoded the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now need to wrap all of this into one function so we can show each step for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original image\n",
    "original_image = create_image_matrix(input_image_asTXT_path, 16, 16)\n",
    "img_width, img_height = original_image.shape\n",
    "\n",
    "# encoding/decoding table\n",
    "huffman_dict = create_bin_dict(22)\n",
    "huffman_dict_rev = {val: key for key, val in huffman_dict.items()}\n",
    "\n",
    "# cases are mapped to int values\n",
    "cases = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# hold all diff matrix for proof it worked\n",
    "diff_matrix_list = []\n",
    "\n",
    "# hold all binary encoded strings for proof/comparison\n",
    "bin_string_list = []\n",
    "\n",
    "# hold all the images to display later\n",
    "reImg_list = []\n",
    "\n",
    "# encode, then decode, each image, add img to `reImg_list`\n",
    "for cur_case in cases:\n",
    "    diff_matrix_cur = create_differences_matrix_with_case(original_image, cur_case)\n",
    "    diff_matrix_list.append(diff_matrix_cur)\n",
    "    \n",
    "    encoded_string_cur = encode_diffMatrix(diff_matrix_cur, huffman_dict)\n",
    "    bin_string_list.append(encoded_string_cur)\n",
    "    \n",
    "    re_img_cur = decode_binaryString_to_diff_matrix(encoded_string_cur, img_width, img_height, huffman_dict_rev, cur_case)\n",
    "    reImg_list.append(re_img_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Matrix: \n",
    "I'll print the second row of each diff matrix (saves on space but still shows it's been calculated).\n",
    "\n",
    "##### Note: the second row is selected since the first row is identical in every case\n",
    "If this works, all the matrixes should be ~different and the first value should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE:  0\n",
      "[ 5. -2.  0. -1.  2.  1.  1.  0.  1.  0. -3.  1.  2.  0.  0.  1.]\n",
      "CASE:  1\n",
      "[ 5.  3.  3.  1.  2.  2.  2.  1.  1.  0. -1. -2. -1. -3. -2.  2.]\n",
      "CASE:  2\n",
      "[ 5.  3.  3.  2.  3.  3.  3.  2.  2.  1. -3.  0.  0. -1. -3. -1.]\n",
      "CASE:  3\n",
      "[ 5. -2.  0. -2.  1.  0.  0. -1.  0. -1. -1. -1.  1. -2.  1.  4.]\n",
      "CASE:  4\n",
      "[ 5. -4.  0. -3.  3.  1.  1. -1.  1. -1. -4.  0.  3. -2.  1.  5.]\n",
      "CASE:  5\n",
      "[ 5.  1.  3. -1.  3.  2.  2.  0.  1. -1. -2. -3.  0. -5. -1.  6.]\n",
      "CASE:  6\n",
      "[ 5.  1.  3.  0.  4.  3.  3.  1.  2.  0. -4. -1.  1. -3. -2.  3.]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i_DM in diff_matrix_list:\n",
    "    print(\"CASE: \", cases[i])\n",
    "    print(i_DM[1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks like it should here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary String:\n",
    "I'll print each binary string (I'll compare them later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE:  0\n",
      "010110001100000000000000010110100000100011010101101010101000101110110100000010010101011000100110001001110000010101101000001101000110000010101011010001000110100011000101010110001000100000110100011101011101000001010110100001010111010000011011010000010101100000001101101000001010110001010001100010111011010001110100000101110110100001010001110110010110101000100010110100101111010110110111100000000100110111010001010101100010111000110010101101010011000101101000101101101011011100001001010100110001011010001011011010110111000010010101001100010110001101101011000101101001100010000000110001011010001010111011010111000010001101000100101101011010001011011010110111000010010100000100010110101101000110101101011101100010001101010001101010011000101101000001010110110110101100010100010110100\n",
      "CASE:  1\n",
      "0101100011000000000000000101101000001000110101011010101010001010001010000010001000100000010110101101101010110101101000100010101000101010001010101000101010001010100101000100000101010101000101010001010001010100100010000010100010001000101011000001000101010000010101000100000101000001000101010001101000100010101010100010100000000000101100010000010000000101001000100000100010100000101000100101011010100001000101000100101011010100010100101010000010100010001010100010001000101000101001010101000101010001010100010000011010101011010101011010101011010101101010110101110001101001111010010100000001001101101011001100101000101100010110110110110010011111111111111111111110111110100100111010010011100011100010111011111011100010011100101111111111011001110011001100101000111011010101111101000001000011001011\n",
      "CASE:  2\n",
      "0101100011000000000000000101101000001000110101011010101010001010001010001000101000101000101000100010000010101111011010101101101000100010101000101010001010101010001010101000001000101000001010001010101000101010100010101001010001000001010001000101000101101011010100010100010100010100010100010100010001101010001000101000000010100010001010100010100010100010011101000110100000100101000100010001101000101010100010001000001000111010010100010000010001110101010001010001000100000100010100010101000001010001010101000001000101010001010001010100010001101011010101010110101010110101010110101101011011000010100101110100010110010001000000101011000010001101001010101101101010110111100001010100110001011010001011011010110111000010010101001100010110001011011010110010100001000100010100001000101101000101101101101101011001100011000100000001011010001011101011010111000010010100000001101011010001101101011110001001010100011010010110101101011010000011100011000101000110100\n",
      "CASE:  3\n",
      "0101100011000000000000000101101000001000110101011010101010001011101011001101110110110110001011000101010001000100100011101010101101001011010101010001011011000101010110001000110100011101010101011010101001000100010101101010001011011010001011010001000101010101101010010101010001010110101111101010110101000001100001010001010110000011000001011010001101011010110101010100010111000100011010110101101010101001010101101010001011010001101000101110101001010101101010100110101101101011010101111001000100000101101010001011111010001011010001110001011101101011010100011100011010001010101101010001010110011010001100111111111111111111111101100110100010110001111010001011000111100010110000010101101000110011011000000010111100011011001111111011010001111000111000111000110100011000110101101010011010001100011011100011011\n",
      "CASE:  4\n",
      "01011000110000000000000001011010000010001101010110101010100010101011101010110101000000011000110101010111010100010110001010101000100010010010001010101010101101010100000101101010101010100010101110100010101010101010110101000100010110101010001011000101010101010101011010101010001000101000101000101010110101010100010101101110101101000101000101010101010101101010101000001010100010101010110101101000001101010101101010101000100010101011010000000001010101101010001000101010110100010101000101011010100010101101011010101101010101010100010101110101000101000101011010110101011010101010101000001010110101010100010101101000101101010001011011010100010001010101011010101010100101101011011010101011010101011011100000100010100000101101010100010111011101010100010101010101101010001010111010001010110001101011010101010100011101000101011010101000101010101011010001010101011110001010001101001010100110001011010001011011010110111000010010101001100010111101101011010100010101011010100011100010001101000101100010110101000101010101100101010101011010010100100011010100010100000101011010110100011010110101011110000100101001010101000101011010110100101010110101100010110001010001011010101010001101010100011010110101010001011010001010001010101110101101010110001010100010101100\n",
      "CASE:  5\n",
      "0101100011000000000000000101101000001000110101011010101010000010100011010100010001001000110101101010111010101010110110101010101000100010101010100010101000101010101000101000101010001010101101010100010010101010101010101010100010001000101010100010101011010001001010101010000010001010101010101011010101010000010100010101010100010110101010101010011010101010001101000101010101000101010101011010101010001000101010101010101010010110000000101010101101010100010100101010000000101010100010101101000101001010100010101000110101010100000101101010101101010101010101000111010001010101000001011010101011010101010101010001010001010110101010101000110101010100000101010101001010001010001010001010110101010101010100010101000101010011010101101010101010101101010101101010101101011010101101101000001010110101010100010111110101010001011010101001000101000101110101101011010101000111010001101010100010101010101101010100010101010111011011010100011010011111111111111111111110101100110101010001011010001111010001011010001111010001010110001000101010101101000101100110110001000101000101111010001101011001111111010110101000111101000111010001110100011010101000110001011010101010110101001101010100101010010111010001101011\n",
      "CASE:  6\n",
      "01011000110000000000000001011010000010001101010110101010100000101001010101000101000101000001001010101011011000101011010110101000100010101000101010001010101000101010100010101010001010110101010001010010101010101010100010100010101000101010100010101011010100010010101010100000101000101010101010110100010100010101000101010100101010101010000000000010001010101000101010110101010001010001010101010000000101000100101010110101000101000101101010000010001000110101000101000101101010001010101010010101010011010101101010101001101010001010100110101011010101010001010100101010101001010100000101010100010000010100010101010001011010101010100010101000101000100000101011010101010110101010101101010101101010110101101100000110101001101110101010001010101101010001100010100011000110101101010100110100010110101010001010101110101010110101101110100101001010100110001011010001011011010110111000010010101001100010111011011010110101000101101010011000100000100011000101101010001010101111010101011110010001101000101000100011010110100011011010101101110000100101001010100010110101101001010110101100011000101000110101010100011010100011010101100010110100010100010110010101100010101000101100\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for i_BS in bin_string_list:\n",
    "    print(\"CASE: \", cases[i])\n",
    "    print(i_BS)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great success!  You can tell right away that some are more performant (in this case) than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And for my final trick, I'll recreate these images from the binary string\n",
    "But first a graphing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_array_figure(reImg_list, cases):\n",
    "    len_cases = len(cases)\n",
    "    fig, axes = plt.subplots(1, len_cases, figsize=(12, 4))\n",
    "    index = 0\n",
    "    for i_img in reImg_list:\n",
    "        axes[index].imshow(i_img, cmap='gray')\n",
    "        i_title = \"CASE: \" + str(cases[index])\n",
    "        axes[index].set_title(i_title)\n",
    "        index += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_array_figure(reImg_list, cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Methods\n",
    "* Compression Ratio\n",
    "    * The number of bits in the original image / Number of bits in the compressed image\n",
    "* Bits/Pixel for the compressed image\n",
    "    * Average number of bits per pixel in the compressed image\n",
    "* RMS Error\n",
    "    * Root-mean-square: the square root of the average of difference between a actual and predicted values, squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_compression_ratio(original_image, encoded_string):\n",
    "    orig_img_w, orig_img_h = original_image.shape\n",
    "    num_pix_orig = orig_img_w * orig_img_h\n",
    "    num_bits_orig = num_pix_orig * 8\n",
    "    num_bits_recreate = len(encoded_string)\n",
    "    comp_ratio = num_bits_orig / num_bits_recreate\n",
    "    return comp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "metrics_cr_list = []\n",
    "for i_BS in bin_string_list:\n",
    "    compression_ratio = calculate_compression_ratio(original_image, i_BS)\n",
    "    metrics_cr_list.append(compression_ratio)\n",
    "    print(\"Case:\", i, \": \", compression_ratio)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Bits/Pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_avg_bitsPerPix(original_image, encoded_string):\n",
    "    img_w, img_h = original_image.shape\n",
    "    num_pix = img_w * img_h\n",
    "    num_bits = len(encoded_string)\n",
    "    avg_bitsPerPix = num_bits / num_pix\n",
    "    return avg_bitsPerPix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "metrics_bitsPix_list = []\n",
    "for i_BS in bin_string_list:\n",
    "    recreated_img = reImg_list[i]\n",
    "    avg_bitsPerPix = calculate_avg_bitsPerPix(recreated_img, i_BS)\n",
    "    metrics_bitsPix_list.append(avg_bitsPerPix)\n",
    "    print(\"Case:\", i, \": \", avg_bitsPerPix)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calulate_RMS_error(original_image, recreated_img):\n",
    "    diff_list_squared = []\n",
    "    row, column = original_image.shape\n",
    "    i = 0\n",
    "    while i < row:\n",
    "        j = 0\n",
    "        while j < column:\n",
    "            img_val = original_image[i][j]\n",
    "            re_val = recreated_img[i][j]\n",
    "            diff = img_val - re_val\n",
    "            diff_squared = diff**2\n",
    "            diff_list_squared.append(diff_squared)\n",
    "            j += 1\n",
    "        i += 1\n",
    "    num_vals = len(diff_list_squared)\n",
    "    sum_vals = sum(diff_list_squared)\n",
    "    RMS_error = math.sqrt(sum_vals/num_vals)\n",
    "    return RMS_error\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "metrics_rms_list = []\n",
    "for i_img in reImg_list:\n",
    "    val = calulate_RMS_error(original_image, i_img)\n",
    "    metrics_rms_list.append(val)\n",
    "    print(\"Case:\", i, \": \", val)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "full_case_tups_list = []\n",
    "i = 0\n",
    "cr_tup_list = []\n",
    "metrics = ['CR', 'Avg', 'RMS']\n",
    "# create compression ratio\n",
    "for case_i in cases:\n",
    "    cur_tup = (case_i, metrics_cr_list[i])\n",
    "    cr_tup_list.append(cur_tup)\n",
    "    i += 1\n",
    "full_case_tups_list.append(cr_tup_list)\n",
    "\n",
    "# create Average Bits/Pixel\n",
    "i = 0\n",
    "avg_tup_list = []\n",
    "for case_i in cases:\n",
    "    cur_tup = (case_i, metrics_bitsPix_list[i])\n",
    "    avg_tup_list.append(cur_tup)\n",
    "    i += 1\n",
    "full_case_tups_list.append(avg_tup_list)\n",
    "\n",
    "# create RMS\n",
    "i = 0\n",
    "rms_tup_list = []\n",
    "for case_i in cases:\n",
    "    cur_tup = (case_i, metrics_rms_list[i])\n",
    "    rms_tup_list.append(cur_tup)\n",
    "    i += 1\n",
    "full_case_tups_list.append(rms_tup_list)\n",
    "\n",
    "for tuple_metric_line in full_case_tups_list:\n",
    "    plt.plot(*zip(*tuple_metric_line), '-o')\n",
    "\n",
    "plt.title('Predictor Methods')\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('case')\n",
    "plt.legend(metrics, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As shown above; \n",
    "* the RMS error is 0 for all cases\n",
    "* the compression ratio and average bits/pixel are inversely related\n",
    "    * this is what we'd expect in this case, as the number of bits/pixel increase the compression ratio should decrease (it is 'less' compressed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do these different predictor functions perform well, where don't they?\n",
    "Let's create some new images and explore the different methods\n",
    "\n",
    "### create new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_width = 16\n",
    "img_height = 16\n",
    "\n",
    "new_imgs_vals = []\n",
    "new_img_labels = []\n",
    "\n",
    "VStriped_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            VStriped_image[i][j] = 20\n",
    "        else:\n",
    "            VStriped_image[i][j] = 40\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    i += 1\n",
    "new_imgs_vals.append(VStriped_image)\n",
    "new_img_labels.append('VStriped')\n",
    "    \n",
    "checkered_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "row_flag = True\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            if row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 30\n",
    "        else:\n",
    "            if not row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 30\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    row_flag = not row_flag\n",
    "    i += 1\n",
    "new_imgs_vals.append(checkered_image)\n",
    "new_img_labels.append('checkered')\n",
    "    \n",
    "    \n",
    "RL_gradient_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "s_val = 50\n",
    "while i < img_width:\n",
    "    r_val = s_val\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        r_val += 1\n",
    "        RL_gradient_image[i][j] = r_val\n",
    "        j += 1\n",
    "    i += 1\n",
    "new_imgs_vals.append(RL_gradient_image)\n",
    "new_img_labels.append('RL_grad')    \n",
    "\n",
    "TDRL_gradient_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "s_val = 50\n",
    "while i < img_width:\n",
    "    r_val = s_val\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        r_val += 1\n",
    "        TDRL_gradient_image[i][j] = r_val\n",
    "        j += 1\n",
    "    i += 1\n",
    "    s_val += 1\n",
    "# plt.imshow(checkered_image, cmap='gray')\n",
    "new_imgs_vals.append(TDRL_gradient_image)\n",
    "new_img_labels.append('TDRL_grad')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_array_figure(new_imgs_vals, new_img_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics for the new cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_all_metics_wrapper(original_image, recreated_img, reImg_list, bin_string_list):\n",
    "    i = 0\n",
    "    metrics_rms_list = []\n",
    "    for i_img in reImg_list:\n",
    "        val = calulate_RMS_error(original_image, i_img)\n",
    "        metrics_rms_list.append(val)\n",
    "        # print(\"Case:\", i, \": \", val)\n",
    "        i += 1\n",
    "    \n",
    "    i = 0\n",
    "    metrics_bitsPix_list = []\n",
    "    for i_BS in bin_string_list:\n",
    "        recreated_img = reImg_list[i]\n",
    "        avg_bitsPerPix = calculate_avg_bitsPerPix(recreated_img, i_BS)\n",
    "        metrics_bitsPix_list.append(avg_bitsPerPix)\n",
    "        # print(\"Case:\", i, \": \", avg_bitsPerPix)\n",
    "        i += 1\n",
    "        \n",
    "    i = 0\n",
    "    metrics_cr_list = []\n",
    "    for i_BS in bin_string_list:\n",
    "        compression_ratio = calculate_compression_ratio(original_image, i_BS)\n",
    "        metrics_cr_list.append(compression_ratio)\n",
    "        # print(\"Case:\", i, \": \", compression_ratio)\n",
    "        i += 1\n",
    "    return metrics_rms_list, metrics_bitsPix_list, metrics_cr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STRIPPED IMAGE\n",
    "# original image shape is retained\n",
    "def calculate_new_metrics_display_plot(current_new_img):\n",
    "    img_width, img_height = VStriped_image.shape\n",
    "    huffman_dict = create_bin_dict(22)\n",
    "    huffman_dict_rev = {val: key for key, val in huffman_dict.items()}\n",
    "    cases = [0, 1, 2, 3, 4, 5, 6]\n",
    "    diff_matrix_list = []\n",
    "    bin_string_list = []\n",
    "    reImg_list = []\n",
    "    for cur_case in cases:\n",
    "        diff_matrix_cur = create_differences_matrix_with_case(current_new_img, cur_case)\n",
    "        diff_matrix_list.append(diff_matrix_cur)\n",
    "\n",
    "        encoded_string_cur = encode_diffMatrix(diff_matrix_cur, huffman_dict)\n",
    "        bin_string_list.append(encoded_string_cur)\n",
    "\n",
    "        re_img_cur = decode_binaryString_to_diff_matrix(encoded_string_cur, img_width, img_height, huffman_dict_rev, cur_case)\n",
    "        reImg_list.append(re_img_cur)\n",
    "    metrics_rms_list, metrics_bitsPix_list, metrics_cr_list = calculate_all_metics_wrapper(current_new_img, recreated_img, reImg_list, bin_string_list)\n",
    "    plt.figure()\n",
    "\n",
    "    full_case_tups_list = []\n",
    "    i = 0\n",
    "    cr_tup_list = []\n",
    "    metrics = ['CR', 'Avg', 'RMS']\n",
    "    # create compression ratio\n",
    "    for case_i in cases:\n",
    "        cur_tup = (case_i, metrics_cr_list[i])\n",
    "        cr_tup_list.append(cur_tup)\n",
    "        i += 1\n",
    "    full_case_tups_list.append(cr_tup_list)\n",
    "\n",
    "    # create Average Bits/Pixel\n",
    "    i = 0\n",
    "    avg_tup_list = []\n",
    "    for case_i in cases:\n",
    "        cur_tup = (case_i, metrics_bitsPix_list[i])\n",
    "        avg_tup_list.append(cur_tup)\n",
    "        i += 1\n",
    "    full_case_tups_list.append(avg_tup_list)\n",
    "\n",
    "    # create RMS\n",
    "    i = 0\n",
    "    rms_tup_list = []\n",
    "    for case_i in cases:\n",
    "        cur_tup = (case_i, metrics_rms_list[i])\n",
    "        rms_tup_list.append(cur_tup)\n",
    "        i += 1\n",
    "    full_case_tups_list.append(rms_tup_list)\n",
    "\n",
    "    for tuple_metric_line in full_case_tups_list:\n",
    "        plt.plot(*zip(*tuple_metric_line), '-o')\n",
    "\n",
    "    plt.title('Predictor Methods')\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('case')\n",
    "    plt.legend(metrics, loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case_index = 0\n",
    "for new_img in new_imgs_vals:\n",
    "    print(\"IMAGE: \", new_img_labels[case_index])\n",
    "    calculate_new_metrics_display_plot(new_img)\n",
    "    case_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's look a little deeper\n",
    "\n",
    "We'll first look at the checkered case;\n",
    "\n",
    "looking at the checkered, let's lee what happens if we alter *how* checkered/different the values are\n",
    "\n",
    "We should, in theory, see the same pattern as above but the chart will be 'expanded' on the vertical axis -- meaning the more checkered the values, the worse the compression is.\n",
    "\n",
    "### Note:\n",
    "Look how well case 2 is performing for checkered -- this is because in this case our predictor value is based on 'C'. which is the diagonal value = in the checker board, the diagonal value doesn't change meaning the difference is zero so in case 2 we only have to encode a small value\n",
    "![predictor functions](./images/predictor_functions.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_width = 16\n",
    "img_height = 16\n",
    "\n",
    "new_imgs_vals = []\n",
    "new_img_labels = []\n",
    "\n",
    "# create small checkered; diff = 1\n",
    "checkered_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "row_flag = True\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            if row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 36\n",
    "        else:\n",
    "            if not row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 36\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    row_flag = not row_flag\n",
    "    i += 1\n",
    "new_imgs_vals.append(checkered_image)\n",
    "new_img_labels.append('checkered_1')\n",
    "\n",
    "# create medium checkered; diff = 2\n",
    "checkered_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "row_flag = True\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            if row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 37\n",
    "        else:\n",
    "            if not row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 37\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    row_flag = not row_flag\n",
    "    i += 1\n",
    "new_imgs_vals.append(checkered_image)\n",
    "new_img_labels.append('checkered_2')\n",
    "\n",
    "\n",
    "# create high checkered; diff = 5\n",
    "checkered_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "row_flag = True\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            if row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 40\n",
    "        else:\n",
    "            if not row_flag:\n",
    "                checkered_image[i][j] = 35\n",
    "            else:\n",
    "                checkered_image[i][j] = 40\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    row_flag = not row_flag\n",
    "    i += 1\n",
    "new_imgs_vals.append(checkered_image)\n",
    "new_img_labels.append('checkered_5')\n",
    "\n",
    "case_index = 0\n",
    "for new_img in new_imgs_vals:\n",
    "    print(\"IMAGE: \", new_img_labels[case_index])\n",
    "    calculate_new_metrics_display_plot(new_img)\n",
    "    case_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By this logic, would we see a similar trend for the vertical stripped image?\n",
    "Yes, let's check, the best case here _should_ be the cases where B has the most influence `CASE 1,3,5` since all values in the column are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_width = 16\n",
    "img_height = 16\n",
    "\n",
    "new_imgs_vals = []\n",
    "new_img_labels = []\n",
    "\n",
    "# create small v_stiped; diff = 1\n",
    "VStriped_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            VStriped_image[i][j] = 20\n",
    "        else:\n",
    "            VStriped_image[i][j] = 21\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    i += 1\n",
    "new_imgs_vals.append(VStriped_image)\n",
    "new_img_labels.append('VStriped_1')\n",
    "\n",
    "# create medium v_stiped; diff = 2\n",
    "VStriped_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            VStriped_image[i][j] = 20\n",
    "        else:\n",
    "            VStriped_image[i][j] = 22\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    i += 1\n",
    "new_imgs_vals.append(VStriped_image)\n",
    "new_img_labels.append('VStriped_2')\n",
    "\n",
    "\n",
    "# create high v_stiped; diff = 5\n",
    "VStriped_image = np.zeros((img_width, img_height))\n",
    "i = 0\n",
    "even_odd = 0\n",
    "while i < img_width:\n",
    "    j = 0\n",
    "    while j < img_height:\n",
    "        if even_odd % 2 == 0:\n",
    "            VStriped_image[i][j] = 20\n",
    "        else:\n",
    "            VStriped_image[i][j] = 25\n",
    "        even_odd += 1\n",
    "        j += 1\n",
    "    i += 1\n",
    "new_imgs_vals.append(VStriped_image)\n",
    "new_img_labels.append('VStriped_5')\n",
    "\n",
    "case_index = 0\n",
    "for new_img in new_imgs_vals:\n",
    "    print(\"IMAGE: \", new_img_labels[case_index])\n",
    "    calculate_new_metrics_display_plot(new_img)\n",
    "    case_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, no?  The compression is better when the differences are smaller and performs best in cases where the `B` value plays a heavy role == `case 1, 3, 5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
